<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Recognition</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <div class="box">
            <img id="capturedImage" src="" alt="Captured Image">
        </div>
        <button id="cameraButton">Capture Image</button>
        <div class="result">
            <div id="english"></div>
            <div id="malay"></div>
            <div id="chinese"></div>
        </div>
        <button id="speakButton">Speak Translation</button>
    </div>
    <script src="script.js"></script>
</body>
</html>

<script>
    const cameraButton = document.getElementById('cameraButton');
    const capturedImage = document.getElementById('capturedImage');
    const englishResult = document.getElementById('english');
    const malayResult = document.getElementById('malay');
    const chineseResult = document.getElementById('chinese');
    const speakButton = document.getElementById('speakButton');

    cameraButton.addEventListener('click', async () => {
        // Your implementation to capture photo from camera or device
        // For simplicity, I'll assume this function returns a base64-encoded image data
        const imageData = await capturePhoto();

        // Show captured image
        capturedImage.src = 'data:image/jpeg;base64,' + imageData;

        // Replace 'YOUR_VISION_API_KEY' with your actual Vision API key
        const object = await recognizeObject(imageData);

        // Replace 'YOUR_TRANSLATION_API_KEY' with your actual Translation API key
        const malayTranslation = await translateText(object, 'en', 'ms');
        const chineseTranslation = await translateText(object, 'en', 'zh');

        // Display results
        englishResult.innerText = object;
        malayResult.innerText = malayTranslation;
        chineseResult.innerText = chineseTranslation;

        // Play audio for Chinese translation
        // Assuming chineseTranslation.audioUrl contains the audio URL
        playAudio(chineseTranslation.audioUrl);
    });

    speakButton.addEventListener('click', async () => {
        // Get translated text
        const chineseTranslation = chineseResult.innerText;

        // Call the function to speak the translated text
        speakText(chineseTranslation);
    });

    async function speakText(text) {
        // Replace 'YOUR_TEXT_TO_SPEECH_API_KEY' with your actual API key
        const apiKey = 'AIzaSyDQUaEzdQy4i-5thYcP4OA5rzMfMYc5BMM';
        const url = `https://texttospeech.googleapis.com/v1/text:synthesize?key=${apiKey}`;

        const requestBody = {
            input: { text: text },
            voice: { languageCode: 'zh-CN', ssmlGender: 'FEMALE' }, // Example voice parameters, adjust as needed
            audioConfig: { audioEncoding: 'MP3' } // Example audio encoding, adjust as needed
        };

        try {
            const response = await fetch(url, {
                method: 'POST',
                body: JSON.stringify(requestBody),
                headers: {
                    'Content-Type': 'application/json',
                },
            });
            const data = await response.json();

            // Assuming data.audioContent contains the audio data
            const audioData = data.audioContent;
            // Your implementation to play audio
            playAudio(audioData);
        } catch (error) {
            console.error('Error synthesizing speech:', error);
        }
    }

    // Function to play audio from binary data
    function playAudio(audioData) {
        // Your implementation to play audio
    }

    // Function to translate text from a source language to a target language
    async function translateText(text, sourceLang, targetLang) {
        const apiKey = 'AIzaSyClrPxLer-VRuWIwtp_9v0xwCViUve5HMc'; // Replace with your Translation API key
        const url = `https://translation.googleapis.com/language/translate/v2?key=${apiKey}&q=${encodeURIComponent(text)}&source=${sourceLang}&target=${targetLang}`;

        try {
            const response = await fetch(url);
            const data = await response.json();
            return data.data.translations[0].translatedText;
        } catch (error) {
            console.error('Error translating text:', error);
            return null;
        }
    }

    // Function to recognize objects in an image data
    async function recognizeObject(imageData) {
        const apiKey = 'AIzaSyCzicyAtpPgLWc6OeZ1AfodA1x4A2LlqY4'; // Replace with your Vision API key
        const url = `https://vision.googleapis.com/v1/images:annotate?key=${apiKey}`;
        const requestBody = {
            requests: [
                {
                    image: {
                        content: imageData,
                    },
                    features: [
                        {
                            type: 'OBJECT_LOCALIZATION',
                        },
                    ],
                },
            ],
        };

        try {
            const response = await fetch(url, {
                method: 'POST',
                body: JSON.stringify(requestBody),
                headers: {
                    'Content-Type': 'application/json',
                },
            });
            const data = await response.json();
            const objects = data.responses[0].localizedObjectAnnotations.map(obj => obj.name);
            return objects;
        } catch (error) {
            console.error('Error recognizing objects:', error);
            return [];
        }
    }

    // Function to capture photo from a camera or device
    async function capturePhoto() {
        // Your implementation to capture photo from camera or device
        // For simplicity, I'll assume this function returns a base64-encoded image data
        return 'BASE64_IMAGE_DATA';
    }
</script>
